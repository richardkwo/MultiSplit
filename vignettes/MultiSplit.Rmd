---
title: "MultiSplit: Properly aggregate multiple data splits and exchangeable p-values"
output: rmarkdown::html_vignette
description: >
  A short intrudction to the basic usage of MultiSplit
vignette: >
  %\VignetteIndexEntry{Put the title of your vignette here}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 5, 
  fig.height = 6, 
  dpi = 150
)
```

This vignette briefly illustrates the use of the package with three "hunt-and-test" procedures that use data splitting for hypothesis testing. Because the way that the data is random, the test constructed is randomized in the sense that the output is a random function of the data. For a dataset, running such a procedure $L$ times produces $L$ different results. This has two obvious drawbacks:

1.  The analysis is not replicable.

2.  Using one single result loses power.

To solve both issues, we should properly aggregate the results from $L$ realizations. Package `MultiSplit` provides a simple framework for such aggregation that guarantees type-I error in large sample.

```{r setup}
library(plyr)
library(MASS)
library(MultiSplit)
library(future)
plan(multisession)   # run inner loop of `test.multisplit` in parallel

set.seed(42)
```

## Testing zero mean

Let $X$ be a random vector. Consider testing the hypothesis that $X$ has mean zero from iid observations. For that purpose, we can randomly divide the sample into two parts of equal size. Let $\hat{\mu}_1$,$\hat{\mu}_2$ be the mean vector of the two parts. If hypothesis holds, we expect $\hat{\mu}_1^{\top} \hat{\mu}_2 \approx 0$; otherwise, we expect $\hat{\mu}_1^{\top} \hat{\mu}_2 > 0$. This motivates the following test statistic $$T_n:=\frac{\sqrt{n / 2} \hat{\mu}_1^\top  \hat{\mu}_2}{\hat{\mu}_1^{\top} \hat{\Sigma}_2 \hat{\mu}_1}, $$

which has a standard normal limit under the null hypothesis $\mathbb{E} X=0$. Here $\hat{\Sigma}_2$ is the sample covariance of the second part. This "single-split" test statistic can be computed with the function below.

```{r}
test.mean.zero.single <- function(X) {
  n <- nrow(X)
  idx.1 <- sample(n, n/2)
  mu.1 <- apply(X[idx.1, ], 2, mean)
  mu.2 <- apply(X[-idx.1, ], 2, mean)
  S.2 <- cov(X[-idx.1, ])
  return(sqrt(n/2) * sum(mu.1 * mu.2) / sqrt(c(mu.1 %*% S.2 %*% mu.1)))
}
```

Let us try it on $X \sim N(\mu, \Sigma)$. The following shows its 
distribution under the null and a (local) alternative (vertical line marks the mean).

```{r, fig.show="hold", out.width="40%"}
p <- 3
n <- 1000
Sigma <- 0.5^outer(1:3, 1:3, "-")
# under the null
stat.single.null <- replicate(200, {
  X <- mvrnorm(n, rep(0, p), Sigma)
  test.mean.zero.single(X)})
hist(stat.single.null, main="H0")
abline(v=mean(stat.single.null), lty=2)
# under the alt
stat.single.alt <- replicate(200, {
  X <- mvrnorm(n, rep(1.7 / sqrt(n), p), Sigma)
  test.mean.zero.single(X)})
hist(stat.single.alt, main="H1")
abline(v=mean(stat.single.alt), lty=2)
```

We can check its level and power at nominal level 0.05.

```{r}
level.single <- mean(stat.single.null > qnorm(0.95))
power.single <- mean(stat.single.alt > qnorm(0.95))
print(level.single)
print(power.single)
```

But this test has high variability **conditional on data**. And its power can be improved as well.

```{r, fig.align='center', echo=TRUE}
X <- mvrnorm(n, rep(0, p), Sigma)
replicate(10, test.mean.zero.single(X))
```

Now suppose we run it $L=50$ times and take the arithmetic average as our aggregated statistic $S_n$. This test statistic's distribution is unknown (and can be unusual) 
under the null and the alternative.

```{r, fig.align='center'}
n.splits <- 50
# under the null
T.mat <- t(replicate(200, {
  X <- mvrnorm(n, rep(0, p), Sigma)
  replicate(n.splits, test.mean.zero.single(X))
}))
S.vec <- apply(T.mat, 1, mean)
hist(S.vec, xlab="S (50 splits)", main="H0")
abline(v=mean(S.vec), lty=2)
# under the alt
T.mat <- t(replicate(200, {
  X <- mvrnorm(n, rep(1.7 / sqrt(n), p), Sigma)
  replicate(n.splits, test.mean.zero.single(X))
}))
S.vec <- apply(T.mat, 1, mean)
hist(S.vec, xlab="S (50 splits)", main="H1")
abline(v=mean(S.vec), lty=2)
```

Nevertheless, statistic $S_n$ can be calibrated automatically by `MultiSplit`. The p-value according to $S_n$ can be computed with function `test.multisplit`.

Here we must specify `q.null` to be the (pivotal, large-sample) null quantile function of the single-split test $T_n$. Statistic $S_n$ is defined through an aggregation function `S`.

Let' s look an instance under the null. 

```{r}
X <- mvrnorm(n, rep(0, p), Sigma)
n.splits <- 50
result <- test.multisplit(X, test.mean.zero.single, 
                          q.null=qnorm, side=1, n.splits=n.splits, 
                          B=100, 
                          verbose=1, .plot=TRUE)
# pvals from 50 splits, and the pval of the aggregated stat
plot(1-pnorm(result$T.obs.vec), xlab="split", ylab="p-value")
abline(h=result$p.value.kde)
```

The plot above shows the individual p-values from the 50 splits, along with the 
p-value corresponding to the aggregated statistic (horizontal line).

Now consider an instance under the alternative.

```{r}
X <- mvrnorm(n, rep(1.7 / sqrt(n), p), Sigma)
n.splits <- 50
result <- test.multisplit(X, test.mean.zero.single, 
                          q.null=qnorm, side=1, n.splits=n.splits, 
                          B=100, 
                          verbose=1, .plot=TRUE)
# pvals from 50 splits, and the pval of the aggregated stat
plot(1-pnorm(result$T.obs.vec), xlab="split", ylab="p-value")
abline(h=result$p.value.kde)
```

The aggregated p-value=`r result$p.value.kde` renders a clear rejection.

## Testing multivariate unimodality

See the single-split `test.unimodal.dip.hunt.single` and the example provided in the documentation for `test.multisplit`.

## Testing goodness-of-fit of quantile regression

See the single-split `gof.quantreg.test.single`, which can be aggregated by `test.multisplit`.
